{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "<a href=\"https://archive.ics.uci.edu/ml/datasets/online+retail\">Online retail</a> is a transnational dataset which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n",
    "\n",
    "## Source\n",
    "\n",
    "UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/online+retail\n",
    "\n",
    "## Business Goal\n",
    "\n",
    "To segment the Customers based on RFM so that the company can target its customers efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T10:16:54.581653Z",
     "start_time": "2020-11-01T10:16:54.570637Z"
    }
   },
   "source": [
    "## Methodology\n",
    "\n",
    "1. [Reading and Understanding the Data](#1) <br>\n",
    "   a. Creating a Data Dictionary\n",
    "2. [Data Cleaning](#2)\n",
    "3. [Data Preparation](#3) <br>\n",
    "   a. Scaling Variables\n",
    "4. [Model Building](#4) <br>\n",
    "   a. K-means Clustering <br>\n",
    "   b. Finding the Optimal K\n",
    "5. [Final Analysis](#5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "\n",
    "### 1 : Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:00.815005Z",
     "start_time": "2020-11-01T13:13:56.682079Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required libraries for dataframe and visualization\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import plotly as py \n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# import required libraries for clustering\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import cut_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:02.085599Z",
     "start_time": "2020-11-01T13:14:00.818009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the data on which analysis needs to be done\n",
    "retail = pd.read_csv('dataset/OnlineRetail.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "# Display first 10 rows\n",
    "retail.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Dictionary\n",
    "\n",
    "| First Header | Definition            | Description                                                                                                                        | Data Type |\n",
    "| ------------ | --------------------- | ---------------------------------------------------------------------------------------------------------------------------------- | --------- |\n",
    "| InvoiceNo    | Invoice number        | A 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation. | Nominal   |\n",
    "| StockCode    | Product (item) code   | A 5-digit integral number uniquely assigned to each distinct product.                                                              | Nominal   |\n",
    "| Description  | Product (item) name   | Name of Product                                                                                                                    | Nominal   |\n",
    "| Quantity     | Quantity              | The quantities of each product (item) per transaction                                                                              | Numeric   |\n",
    "| InvoiceDate  | Invoice Date and time | The day and time when each transaction was generated.                                                                              | Numeric   |\n",
    "| UnitPrice    | Unit price            | Product price per unit in sterling.                                                                                                | Numeric   |\n",
    "| CustomerID   | Customer number       | A 5-digit integral number uniquely assigned to each customer.                                                                      | Nominal   |\n",
    "| Country      | Country name          | The name of the country where each customer resides.                                                                               | Nominal   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = retail.isnull().sum()\n",
    "\n",
    "# Filter columns with missing values (optional, can remove if you want all columns)\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "# Plot the missing values\n",
    "plt.figure(figsize=(10, 6))\n",
    "missing_values.plot(kind='bar', color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Missing Values per Column', fontsize=16)\n",
    "plt.xlabel('Columns', fontsize=12)\n",
    "plt.ylabel('Number of Missing Values', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the majority of the missing values is in the Customer ID. Since Customer ID is a sensitive column, and we cannot make justifications o assumptions of the number of customers coming in to buy as it may cause some data inconsistencies and be the cause of misrepresentation of sensitive sales data, we drop the missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the null customer id rows\n",
    "retail_cleaned = retail.copy()\n",
    "retail_cleaned = retail_cleaned.dropna(subset=['CustomerID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to derive the meaning of the descriptions of the items using Stock Code, and try to fill in missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_code_to_description = retail_cleaned.dropna(subset=['Description']).set_index('StockCode')['Description'].to_dict()\n",
    "\n",
    "# Fill missing descriptions using the dictionary\n",
    "retail_cleaned['Description'] = retail_cleaned.apply(\n",
    "    lambda row: stock_code_to_description.get(row['StockCode']) if pd.isnull(row['Description']) else row['Description'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Drop rows where the description is still missing\n",
    "df_cleaned = retail_cleaned.dropna(subset=['Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if missing values are no more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "\n",
    "### 2 : Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:02.686138Z",
     "start_time": "2020-11-01T13:14:02.492125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculating the Missing Values % contribution in DF\n",
    "total_rows = len(retail)\n",
    "\n",
    "# Calculate the number of missing values per column\n",
    "missing_values = retail.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values per column\n",
    "missing_percentage = (missing_values / total_rows) * 100\n",
    "\n",
    "# Filter only columns with missing values (optional, can remove if you want all columns)\n",
    "missing_percentage = missing_percentage[missing_percentage > 0]\n",
    "\n",
    "# Display the missing percentage for each column\n",
    "missing_percentage = missing_percentage.sort_values(ascending=False)\n",
    "print(missing_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:03.209183Z",
     "start_time": "2020-11-01T13:14:02.890175Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changing the datatype of Customer Id as per Business understanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "\n",
    "### 3 : Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customers will be analyzed based on 3 factors:\n",
    "\n",
    "- R (Recency): Number of days since last purchase\n",
    "- F (Frequency): Number of tracsactions\n",
    "- M (Monetary): Total amount of transactions (revenue contributed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_cleaned['InvoiceDate'] = pd.to_datetime(retail_cleaned['InvoiceDate'], format=\"%d-%m-%Y %H:%M\", errors='coerce')\n",
    "\n",
    "# Step 2: Compute the maximum date to determine the last transaction date\n",
    "last_transaction_date = retail_cleaned['InvoiceDate'].max()\n",
    "print(f\"Last transaction date: {last_transaction_date}\")\n",
    "\n",
    "# Step 3: Compute Recency, Frequency, and Monetary for each customer\n",
    "rfm = retail_cleaned.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': lambda x: (last_transaction_date - x.max()).days,  # Recency: Days since last purchase\n",
    "    'InvoiceNo': 'nunique',                                           # Frequency: Number of unique transactions\n",
    "    'UnitPrice': lambda x: np.sum(x * retail_cleaned.loc[x.index, 'Quantity'])    # Monetary: Total spending per customer\n",
    "}).reset_index()\n",
    "\n",
    "# Step 4: Rename the columns to represent RFM\n",
    "rfm.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "# Step 5: Display the resulting RFM table\n",
    "print(rfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:03.522238Z",
     "start_time": "2020-11-01T13:14:03.496236Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merging the two dfs\n",
    "retail_final = pd.merge(retail_cleaned, rfm, on='CustomerID', how='inner')  # You can change 'how' to 'outer', 'left', or 'right' as needed\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(retail_final.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rescaling the Attributes\n",
    "\n",
    "It is extremely important to rescale the variables so that they have a comparable scale.<br>\n",
    "There are two common ways of rescaling:\n",
    "\n",
    "1. Min-Max scaling\n",
    "2. Standardization (mean-0, sigma-1)\n",
    "\n",
    "Here we execute Standard Scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:05.483386Z",
     "start_time": "2020-11-01T13:14:05.460385Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rescaling the attributes\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "features = ['Monetary', 'Frequency', 'Recency']  \n",
    "X = retail_final[features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: red;\">Execute MinMax Scaling in the next box</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled)\n",
    "X_scaled.columns = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "\n",
    "### 4 : Clustering Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.<br>\n",
    "\n",
    "The algorithm works as follows:\n",
    "\n",
    "- First we initialize k points, called means, randomly.\n",
    "- We categorize each item to its closest mean and we update the meanâ€™s coordinates, which are the averages of the items categorized in that mean so far.\n",
    "- We repeat the process for a given number of iterations and at the end, we have our clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:05.629395Z",
     "start_time": "2020-11-01T13:14:05.508388Z"
    }
   },
   "outputs": [],
   "source": [
    "# k-means with some arbitrary k\n",
    "Kmeans = KMeans(n_clusters=4, max_iter=50)\n",
    "Kmeans.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "\n",
    "for i in range (1,8):\n",
    "    kmeans = KMeans(n_clusters=i, init = 'k-means++', max_iter=300, n_init=7, random_state=0)\n",
    "    kmeans.fit(X_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1,8), wcss)\n",
    "plt.title('The elbow method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:05.651399Z",
     "start_time": "2020-11-01T13:14:05.644399Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a K_means function here\n",
    "def K_Mean(X, n):\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    model = KMeans(n)\n",
    "    model.fit(X)\n",
    "    clusters = model.predict(X)\n",
    "    cent = model.cluster_centers_\n",
    "    return (clusters, cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, cent = K_Mean(X_scaled, 3)\n",
    "kmeans = pd.DataFrame(clusters)\n",
    "retail_final.insert((retail_final.shape[1]), 'kmeans', kmeans)\n",
    "retail_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:53:55.898917Z",
     "start_time": "2020-11-01T13:53:55.746885Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot your clusters\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Use the cluster column to color the points\n",
    "scatter = ax.scatter(retail_final[features[0]], retail_final[features[1]], retail_final[features[2]], \n",
    "                     c=retail_final['kmeans'], cmap='viridis', marker='o', edgecolor='k')\n",
    "\n",
    "# Set labels for the axes\n",
    "ax.set_xlabel(features[0])\n",
    "ax.set_ylabel(features[1])\n",
    "ax.set_zlabel(features[2])\n",
    "\n",
    "# Add a color bar to show cluster labels\n",
    "legend1 = ax.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "# Add a title\n",
    "plt.title('3D Scatter Plot of K-means Clusters')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: red;\">Box Plots of Clusters created</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "\n",
    "## Step 5 : Final Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: red;\">Findings</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSELEC3C",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
